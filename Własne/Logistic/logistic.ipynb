{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic():\n",
    "    '''Implementacja modelu regresji logistycznej trenowana poprzez użycie SGD z momentum '''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "        self.conf_matrix = None\n",
    "\n",
    "    \n",
    "    def sigmoid(self,X:np.ndarray) -> float:\n",
    "        return 1/(1+np.exp(-X))\n",
    "    \n",
    " \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray,iterations=10,learning_rate=0.01,gamma=0.9,C=1.0) ->None:\n",
    "        '''Zdecydowałem się na użycie regularyzacji, aby poprawić wyniki algorytmu. Jej mocą steruje się poprzez odpowiednie ustawienie parametru C,\n",
    "            domyślnie jest on ustawiony na 1. Ponadto można ustawić ilość iteracji algorytmu, tempo ucznenia, a także moc momentum. '''\n",
    "        assert C !=0\n",
    "        m = X.shape[0]\n",
    "        n = X.shape[1]+1\n",
    "        X_b = np.c_[np.ones((m,1)),X]\n",
    "        velocity = 0 \n",
    "        self.theta = np.random.randn(n,1) \n",
    "        lamb = 1/C\n",
    "        for iteration in range(iterations):\n",
    "            for i in range(m):\n",
    "                random_index = np.random.randint(m)\n",
    "                xi = X_b[random_index:random_index+1]\n",
    "                yi = y[random_index:random_index+1]\n",
    "                sigm = self.sigmoid(xi @ self.theta)\n",
    "                gradient = xi.T.dot (sigm - yi) + (lamb/m)*(self.theta)\n",
    "                velocity = gamma * velocity\n",
    "                speed = learning_rate*gradient +velocity\n",
    "                self.theta = self.theta - speed\n",
    "        return\n",
    "    \n",
    "    def coef(self) -> np.ndarray:\n",
    "        '''Funkcja zwracająca parametry wytrenowane przez model '''\n",
    "        return self.theta\n",
    "    \n",
    "    def validate(self,X: np.ndarray,y:np.ndarray,cv=5,C=1) -> str:\n",
    "        '''Funkcja wykonująca kroswalidacje poprzez podzielenie zbioru na cv podzbiorów, a nastepnie iteracyjne tranowanie modelu na cv-1 częsciach, a \n",
    "            następnie sprawdzanie wyników na pozostałym zbiorze. W efekcie mamy cv wyników które są uśredniane i zwracane przez funkcje '''\n",
    "        size = X.shape[0]\n",
    "        scores = []\n",
    "        perm = np.random.permutation(size)\n",
    "        X_b = X[perm]\n",
    "        y_b = y[perm]\n",
    "        X_b = np.array(np.array_split(X_b,cv))\n",
    "        y_b = np.array(np.array_split(y_b,cv))\n",
    "        mask = np.ones(cv,dtype=bool) #Pomocnicza tablica do wybierania odpowiednich podtablic\n",
    "        for i in range(cv):\n",
    "            mask[i] = 0\n",
    "            X_val = X_b[mask==0][0]\n",
    "            y_val = y_b[mask==0][0]\n",
    "            res = X_b.shape[0] -y_val.shape[0]\n",
    "            X_fit = X_b[mask].reshape(res,(28*28))\n",
    "            y_fit = y_b[mask].reshape(res,)\n",
    "            self.fit(X_fit,y_fit,C=C)\n",
    "            pred = self.predict(X_val)\n",
    "            score =  self.evaluate(y_val,pred)\n",
    "            scores.append(score)\n",
    "            mask[i] = 1\n",
    "        return f'Mean = {np.mean(scores)}, Std = {np.std(scores)}'\n",
    "            \n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        '''Funckja do przewidywania na podstawie wcześniej wytrenowanych parametrów'''\n",
    "        m = X.shape[0]\n",
    "        X_b = np.c_[np.ones((m,1)),X]\n",
    "        return np.round(self.sigmoid(X_b @ self.theta))\n",
    "    \n",
    "\n",
    "    def evaluate(self,y_true: np.ndarray, y_pred: np.ndarray) ->float:\n",
    "        '''Funckja mierząca accuracy '''\n",
    "        assert y_true.shape[0] == y_pred.shape[0]\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for i in range(len(y_true)):\n",
    "            if y_true[i]==1 and y_true[i] == y_pred[i]:\n",
    "                TP +=1\n",
    "            elif y_true[i]==0 and y_true[i] == y_pred[i]:\n",
    "                TN +=1\n",
    "            elif  y_true[i] > y_pred[i]:\n",
    "                FN+=1\n",
    "            elif y_pred[i]>y_true[i]:\n",
    "                FP +=1\n",
    "        accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
    "        self.conf_matrix = np.array([[TP,FP],[FN,TN]])\n",
    "        return accuracy\n",
    "\n",
    "    def confusion(self) ->np.ndarray:\n",
    "        '''Funkcja zwracająca macierz pomyłek '''\n",
    "        return self.conf_matrix\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMNIST( prefix, folder ):\n",
    "    '''Funkcja do ładowania zbiou danych z pliku ubyte '''\n",
    "    intType = np.dtype( 'int32' ).newbyteorder( '>' )\n",
    "    nMetaDataBytes = 4 * intType.itemsize\n",
    "\n",
    "    data = np.fromfile( folder + \"/\" + prefix + '-images-idx3-ubyte', dtype = 'ubyte' )\n",
    "    magicBytes, nImages, width, height = np.frombuffer( data[:nMetaDataBytes].tobytes(), intType )\n",
    "    data = data[nMetaDataBytes:].astype( dtype = 'float32' ).reshape( [ nImages, width, height ] )\n",
    "\n",
    "    labels = np.fromfile( folder + \"/\" + prefix + '-labels-idx1-ubyte',\n",
    "                          dtype = 'ubyte' )[2 * intType.itemsize:]\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def delete_elems(X,y):\n",
    "    '''Usunięcie elementów zawierających 0 bądź 1, zgodnie z poleceniem'''\n",
    "    index = np.argwhere(np.logical_or(y==0,y==1))\n",
    "    X = np.delete(X,index,axis=0)\n",
    "    y= np.delete(y,index)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def change_labels(y):\n",
    "    '''Odpowiednie ustawienie labeli, tak że 1 odpowiada liczbom pierwszym, a 0 liczbom złożonym '''\n",
    "    index_prime = np.argwhere(np.logical_or.reduce((y==2,y==3,y==5,y==7)))\n",
    "    index_composite = np.argwhere(np.logical_or.reduce((y==4,y==6,y==8,y==9)))\n",
    "    y[index_prime] = 1\n",
    "    y[index_composite] = 0 \n",
    "    return y\n",
    "\n",
    "def resize(X):\n",
    "    '''Przeskalowanie zbioru danych, do przedziału [0,1] '''\n",
    "    n = X.shape[0]\n",
    "    X = X.reshape(n,28*28)\n",
    "    X = X/255\n",
    "    return X\n",
    "\n",
    "def shuffle(X,y):\n",
    "    '''Funkcja do losowego przemieszania zbioru '''\n",
    "    perm= np.random.permutation(X.shape[0])\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare():\n",
    "    '''Funckja służąca jako wraper, przygotowujący zbiór danych do odpalenia na nim modelu '''\n",
    "    X_train, y_train = loadMNIST( \"train\", \"./Allegro_data\")\n",
    "    X_test, y_test = loadMNIST( \"t10k\", \"./Allegro_data\" )\n",
    "    X_train,y_train = delete_elems(X_train,y_train)\n",
    "    X_test,y_test = delete_elems(X_test,y_test)\n",
    "    y_train = change_labels(y_train)\n",
    "    y_test = change_labels(y_test)\n",
    "    X_train = resize(X_train)\n",
    "    X_test = resize(X_test)\n",
    "    X_train,y_train = shuffle(X_train,y_train)\n",
    "    X_test,y_test = shuffle(X_test,y_test)\n",
    "    return X_train,X_test,y_train,y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W celu uzyskania jak najlepszych parametrów zdecydowałem się na użycie walidacji krzyżowej. Zdecydowałem się robić walidację jedynie zmieniając parametr C, uznając pozostałe jako stałe elementy SGD, tzn.jako takie których nie warto modyfikować."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Mean = 0.9028625752614344, Std = 0.003584332408898654', 'C = 0.01')\n",
      "('Mean = 0.9042146403295657, Std = 0.0046975825152130194', 'C = 0.1')\n",
      "('Mean = 0.9056934614978346, Std = 0.00584064637629604', 'C = 1')\n",
      "('Mean = 0.9070666525826555, Std = 0.004567521025467034', 'C = 10')\n",
      "('Mean = 0.9062638639484526, Std = 0.0039026563570105244', 'C = 100')\n"
     ]
    }
   ],
   "source": [
    "C_val = [0.01,0.1,1,10,100]\n",
    "scores = []\n",
    "for i in range(len(C_val)):\n",
    "    X_train,X_test,y_train,y_test = prepare()\n",
    "    logistic = Logistic()\n",
    "    score = logistic.validate(X_train,y_train,C = C_val[i])\n",
    "    tup = (score,f'C = {C_val[i]}')\n",
    "    scores.append(tup)\n",
    "print(*scores, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widać że wyniki są stabilne, praktycznie nie występują odchylenia w wyniku w trakcie zmian parametru regularyzacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3624,  315],\n",
       "       [ 338, 3608]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = prepare()\n",
    "logistic = Logistic()\n",
    "logistic.fit(X_train,y_train)\n",
    "pred = logistic.predict(X_test)\n",
    "score =logistic.evaluate(y_test,pred)\n",
    "logistic.confusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macierz pomyłek potwierdza poprzednie dobre wyniki, jednocześnie pokazując, że istnieje pole do poprawy,jednakże ciężko będzie to osiągnąc tym algorytmem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9171845275840202"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uważam iż udało mi się osiągnąc dobre wyniki. Accuracy na zbiorze testowym na poziomie 91-92% jest wynikiem porównywalnym z wynikiem, który osiągnęła implementacja tego samego algorytmu w bibliotece Scikit-Learn. Mogę stwierdzić iż regularyzacja, oraz użycie momentum znacząco poprawiło działanie algorytmu. Obie metody poprawiły accuracy, a także pozwoliły ustabilizować wyniki. Jeśli chodzi o analizę błędów popełnianych przez algorytm, to jest to dość utrudnione ze wzgłędu na sformułwanie problemu dzielące zbiór na liczby pierwsze i złożone, przez co, nie można zdecydowanie stwierdzić na jakich cyfrach algorytm myli się najczęsciej. Aby osiągnąć lepsze accuracy należałoby użyć algorytmu zdolnego analizować bardziej skomplikowane wzorce, jak na przykład SVM."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('wum_projekt_1': conda)",
   "language": "python",
   "name": "python37664bitwumprojekt1condaed2b3fa0ea9545aa93fe4c48967ebc97"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
