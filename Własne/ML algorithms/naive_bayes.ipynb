{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiNB():\n",
    "    def __init__(self):\n",
    "        self.theta_y = None\n",
    "        self.theta_y_one = None\n",
    "        self.theta_y_zero = None\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        m,n = X.shape\n",
    "        positive = np.where(y==1)\n",
    "        negative = np.where(y==0)\n",
    "        self.theta_y = np.array(positive).shape[1]/m\n",
    "        X_positive = X[positive]\n",
    "        X_negative = X[negative]\n",
    "        \n",
    "        \n",
    "        theta_y1 = np.sum(X[positive],axis=0)+1\n",
    "        V = n\n",
    "        d_positive = np.sum(np.count_nonzero(X_positive.toarray(),axis=1))\n",
    "        self.theta_y_one = theta_y1/(V+d_positive)\n",
    "\n",
    "\n",
    "        theta_y0 = np.sum(X[negative],axis=0)+1\n",
    "        d_negative = np.sum(np.count_nonzero(X_negative.toarray(),axis=1))\n",
    "        self.theta_y_zero = theta_y0/(V+d_negative)\n",
    "        return\n",
    "        \n",
    "    def predict(self,X):\n",
    "        nonzero = np.array(np.nonzero(X))\n",
    "        X[nonzero[0],nonzero[1]] = self.theta_y_one[:,nonzero[1]]\n",
    "        maska = np.ma.masked_equal(X.toarray(),0)\n",
    "        prodcuts = np.array([0]).astype(np.longdouble)\n",
    "        products = maska.product(axis=1).data\n",
    "        ones_prod = products * self.theta_y\n",
    "\n",
    "\n",
    "        nonzero = np.array(np.nonzero(X))\n",
    "        X[nonzero[0],nonzero[1]] = self.theta_y_zero[:,nonzero[1]]\n",
    "        maska = np.ma.masked_equal(X.toarray(),0)\n",
    "        prodcuts = np.array([0]).astype(np.longdouble)\n",
    "        products = maska.product(axis=1).data\n",
    "        zero_prod = products * (1-self.theta_y)\n",
    "\n",
    "        \n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            denominator = ones_prod + zero_prod\n",
    "            output  = np.true_divide(ones_prod,denominator)\n",
    "            output[output== np.inf] = 0\n",
    "            output = np.nan_to_num(output)\n",
    "\n",
    "        output= np.round(output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "df = pd.read_csv('./IMDB.csv')\n",
    "df = df[:3000]\n",
    "\n",
    "def get_text(text):\n",
    "    soup = BeautifulSoup(text,'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "def rm_special(text):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "df['review'] = df['review'].apply(get_text)\n",
    "df['review'] = df['review'].apply(rm_special)\n",
    "df['sentiment'] = df['sentiment'].map({'positive':1,'negative':0})\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = [word for word in text if not word in stop]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "df['review'] = df['review'].apply(lemma)\n",
    "\n",
    "\n",
    "\n",
    "def stop_words_token(text):\n",
    "    tokenizer = ToktokTokenizer()\n",
    "    tokened = tokenizer.tokenize(text)\n",
    "    text = [token for token in tokened if token not in stop]\n",
    "    text = ' '.join(text) \n",
    "    return text\n",
    "df['review'] = df['review'].apply(stop_words_token)\n",
    "\n",
    "y = df['sentiment']\n",
    "df.drop(['sentiment'],axis=1,inplace=True)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(df,y,test_size=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv=TfidfVectorizer(min_df=0,max_df=1,ngram_range=(1,3))\n",
    "#tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True)\n",
    "train_data = tv.fit_transform(X_train['review'])\n",
    "test_data = tv.transform(X_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.685"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultiNB()\n",
    "nb.fit(train_data,y_train)\n",
    "pred = nb.predict(test_data)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5033333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_data,y_train)\n",
    "pred = nb.predict(test_data)\n",
    "accuracy_score(y_test,pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('TF_learn': conda)",
   "language": "python",
   "name": "python37764bittflearncondad80b0f024ab6498da11fd9b9265393ab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
